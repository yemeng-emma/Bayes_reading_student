---
title: "Week2"
author: "Meng Ye"
date: "2022-08-31"
output: html_document
---

```{r load packages, message=FALSE, warning=FALSE}
library(bayesrules)
library(tidyverse)
library(janitor)
```

# Bayes Rules Chapter 2

## Follow along Bayes Rules Chapter 2

### Intro

```{r}
# Import article data
data(fake_news)
```

ps: data takes some to load...


```{r}
fake_news %>% 
  tabyl(type) %>% 
  adorn_totals("row")
```

ps: get to know a new way to derive the "pretend" row of summed up data, but maybe compared with our earlier `add_row()` approach, the types of calculation for the summed up row might be limited to only `sum()`.

```{r}
# Tabulate exclamation usage and article type
fake_news %>% 
  tabyl(title_has_excl, type) %>% 
  adorn_totals("row")
```



### 2.1 Building a Beyesian model for the events 

- Conditional vs. unconditional probability

- Definition of independent events:

  if and only if $P(A|B) = P(A)$
  
- Probability vs. Likelihood 
  Notice that the prior probabilities add up to 1 but the likelihoods do not. Again, the likelihood function is not a probability function, but rather provides a framework to compare the relative compatibility of our aclamation point data with $B$ and $B^c$.
  
  likelihood function defined as:
  
  $L(B|A) = P(A|B)$ and $L(B^c|A) = P(A|B^c)$
  
- Marginal probability and the LTP 

```{r}
# try out the calculation by adapting author's code
fake_news %>% 
  tabyl(title_has_excl, type) %>% 
  adorn_totals("row") %>% 
  adorn_totals("col") %>% 
  mutate(across(where(is.numeric), ~ ./150)) %>% 
  adorn_rounding(digits = 4)
```


This is calculation in Table 2.3.

#### 2.1.5 Posterier simulation 
```{r}
# Define possible articles
article <- data.frame(type = c("real", "fake"))

# Define the prior model
prior <- c(0.6, 0.4)

# Simulate 3 articles
set.seed(84735)
sample_n(article, size = 3, weight = prior, replace = TRUE)
```
ps. Have some trivil questions:

How does R know to correspond the order of `article` and `prior` 
`replace = TRUE` is R code way to say "put the ball drawn back to the bag"? and `replace = FALSE` is not puting the ball back? 


```{r}
# Simulate 10000 articles. 
set.seed(84735)

article_sim <- sample_n(article, size = 10000, 
                        weight = prior, replace = TRUE)
# skip the (ugly) bar chart

# tab of the 10000 sample
article_sim %>% 
  tabyl(type) %>% 
  adorn_totals("row")

```


```{r}
# simulate the exclamation points
article_sim <- article_sim %>% 
  mutate(data_model = case_when(type == "fake" ~ 0.2667,
                                type == "real" ~ 0.0222))

glimpse(article_sim)
```

```{r}
# Define whether there are exclamation points
data <- c("no", "yes")

# Simulate exclamation point usage 
set.seed(3)
article_sim <- article_sim %>%
  group_by(1:n()) %>% 
  mutate(usage = sample(data, size = 1, 
                        prob = c(1 - data_model, data_model)))
```

ps: in these simulations what we feed first to `sample()` or `sample_n()` is the "sample space"? 

"Note that `sample()` is similar to `sample_n()` but samples values from vectors instead of rows from data frames."

`sample()` uses "prob", and `sample_n()` uses "weights". 


```{r}
article_sim %>% 
  tabyl(usage, type) %>% 
  adorn_totals(c("col","row"))
```

ps: ok, learned one more trick, you can do row and col together with `c()`

```{r}
# adapted bar chart
ggplot(article_sim, aes(x = type, fill = type)) + 
  geom_bar(width = 0.6) + 
  facet_wrap(~ fct_rev(usage)) +
  theme_bw()
```

### 2.2 Example: pop vs soda vs coke

```{r}
# Load the data
data(pop_vs_soda)

# Summarize pop use by region
pop_vs_soda %>% 
  tabyl(pop, region) %>% 
  adorn_percentages("col")  %>% 
  adorn_rounding(digits = 4)
```



### 2.3 Building a Bayesian model for random variables 

pivoting from categorical variables to **numerical** variables 

- the Binomial model 

notation:

$Y|\pi \sim Bin (n, \pi)$

ps. the meaning of "parameters"?
In my earlier stats training "parameters" are the true value of the estimated coefficients in the "population". Here it seems to mean something different, my understanding is that: parameters means sth set, what is not "random variables"


- normalizing constant:
  can be treated just as a constant $c$
  
- posterior shortcut:

  $posterior \propto prior \cdot likelihood$
  
- posterior simulation
  
```{r}
# Define possible win probabilities
chess <- data.frame(pi = c(0.2, 0.5, 0.8))

# Define the prior model
prior <- c(0.10, 0.25, 0.65)

# Simulate 10000 values of pi from the prior
set.seed(84735)
chess_sim <- sample_n(chess, size = 10000, weight = prior, replace = TRUE)

# Simulate 10000 match outcomes
chess_sim <- chess_sim %>% 
  mutate(y = rbinom(10000, size = 6, prob = pi))

# Check it out
chess_sim %>% 
  head(3)
```

```{r}
# Summarize the prior
chess_sim %>% 
  tabyl(pi) %>% 
  adorn_totals("row")
```

```{r}
# Plot y by pi
ggplot(chess_sim, aes(x = y)) + 
  stat_count(aes(y = ..prop..)) + 
  facet_wrap(~ pi)
```

```{r}
# Focus on simulations with y = 1
win_one <- chess_sim %>% 
  filter(y == 1)

# Summarize the posterior approximation
win_one %>% 
  tabyl(pi) %>% 
  adorn_totals("row")


# Plot the posterior approximation
ggplot(win_one, aes(x = pi)) + 
  geom_bar()
```

## Questions for the chapter

1. Needs more explanation of the definition of marginal probability, or better -- marginal prob. vs. conditional prob. vs. combined prob.


2. In a real research question, which corresponds to prior, which corresponds to postierior?

3. How Bayesian model is different from MLE? 

4. Does the prior and posterior elements of Bayesian models necessarily indicate there should be temporal dimension to the data analyzed?  



## Practices for Beyes Rules Chapter 2

### Excercise 2.2 

We went through it together today (9/1). 

### Excercise 2.4

$ P(V) = 0.05$ , $P(V^c) = 0.95$
$ P(S|V) = 0.7$, $P(S|V^c) = 0.03$ 

$$
P(V|S) = \frac{P(S|V) \cdot P(V)}{P(S|V) \cdot P(V) + P(S|V^c) \cdot P(V^c)} = 0.7*0.05/(0.7*0.05 + 0.03*0.95) = 0.55
$$

```{r}
0.7*0.05/(0.7*0.05 + 0.03*0.95)
```



### Excercise 2.13 

I know how to calculate but don't know how to guess before doing the calculation?

```{r}
# creating the data frame borrow the data.frame() function in the text book  
intolerant <- data.frame(pi_value = c(0.4, 0.5, 0.6, 0.7)) %>% 
  bind_cols(pi_prior = c(0.1, 0.2, 0.44, 0.26)) %>% 
  mutate(likelihood = choose(80,47) * pi_value^47 * (1 - pi_value)^(80-47)) %>%
  mutate(updating_product = pi_prior * likelihood) %>% 
  mutate(normalizing = sum(updating_product)) %>% 
  mutate(pi_posterior = updating_product/normalizing)

intolerant$pi_posterior
```

### Excercise 2.14 


```{r}
# creating the data frame borrow the data.frame() function in the text book  
latebus <- data.frame(pi_value = c(0.15, 0.25, 0.5, 0.75, 0.85)) %>% 
  bind_cols(pi_prior = c(3, 3, 8, 3, 3)/20) %>% 
  mutate(likelihood = choose(13, 3) * pi_value^3 * (1 - pi_value)^(13 - 3)) %>%
  mutate(updating_product = pi_prior * likelihood) %>%
  mutate(normalizing = sum(updating_product)) %>% 
  mutate(pi_posterior = updating_product/normalizing)

latebus$pi_posterior
```

The probability to be late seems to be smaller than what people think. 


### Excercise 2.18

Repeat Exercise 2.13 we did earlier. 

```{r}
set.seed(5431)
# possible values or sample space?
intolerant_value <- data.frame(pi_value = c(0.4, 0.5, 0.6, 0.7))

# define the prior model 
intol_pi_prior = c(0.1, 0.2, 0.44, 0.26)

# Simulation of 10000 pi from the prior 
intol_sim <- sample_n(intolerant_value, size = 10000, weight = intol_pi_prior, replace = TRUE)

# generate simulated outcome based on the above parameters
intol_sim <- intol_sim %>% 
  mutate(outcome = rbinom(10000, size = 80, prob = pi_value))

# check the simulated data
intol_sim %>% 
  tabyl(pi_value) %>% 
  adorn_totals("row")
```

```{r}
# check the prob distribution for outcome == 47
intol_sim %>% 
  filter(outcome == 47) %>% 
  tabyl(pi_value) %>% 
  adorn_totals()
```


```{r}
# compare
intolerant$pi_posterior
```
Roughly the same


### Excercise 2.20

I am not totally certain if I get this one right. 

```{r}
set.seed(5431)
# possible values or sample space?
cats_value <- data.frame(pi_value = c(1, 0))

# define the prior model 
cats_pi_prior = c(0.08, 0.92)

# Simulation of 10000 pi from the prior 
cats_sim <- sample_n(cats_value, size = 10000, weight = cats_pi_prior, replace = TRUE) %>% 
  mutate(index = 1:n())

# check distribution
mean(cats_sim$pi_value)
```

the "pi_value" is not actually proportions, but I am keeping the name to remind me structurally which element it corresponds to in other models. 

```{r}
# generate simulated data for false positive
cats_correct_fp <- cats_sim %>% 
  filter(pi_value == 1) %>% 
  sample_n(size = n() * (1-0.8), replace = FALSE) %>% 
  mutate(pi_true_value = 0)
# check generated data
nrow(cats_correct_fp)
```

```{r}
# generate simulated data for false negative
cats_correct_fn <- cats_sim %>% 
  filter(pi_value == 0) %>% 
  sample_n(size = n() * 0.5, replace = FALSE) %>% 
  mutate(pi_true_value = 1)

# check generated data
nrow(cats_correct_fn)
```


```{r}
# combine the wrongfully identified sub data sets
cats_correct <- bind_rows(cats_correct_fn, cats_correct_fp)

# check if it is correct
cats_correct %>% 
  mutate(summ = pi_value + pi_true_value) %>% 
  pull(summ) %>% 
  sd()
```


```{r}
# combine the identified results and the true results
cats_correct_merge <- cats_correct %>% 
  select(- pi_value)

cats_sim_updated <- cats_sim %>% 
  left_join(cats_correct_merge, by = "index") %>% 
  mutate(pi_true_value = ifelse(is.na(pi_true_value), pi_value, pi_true_value))
```

$$ P(pi-true-value =1|pi-value =1) = \frac{P(pi-true-value=1 \cap pi -value =1)}{P(pi-value =1)}$$
```{r}
nrow(filter(cats_sim_updated, pi_value == 1 & pi_true_value ==1))/nrow(filter(cats_sim_updated, pi_true_value ==1))
```

Am I supposed to do this calculation since I am simulating...?

# Bayes Rules Chapter 3

## Follow along Bayes Rules Chapter 3

### Intro

- Beta-Binomial Bayesian model

a continuous prior probability model of $\pi$, provides us the tools we need to study the proportion of interest,

### 3.1 Beta prior model 

- pdf ~ pmf for discrete variables and integrates to 1, probability is the area

- A hyperparameter is a parameter used in a prior model

- Question for Equation 3.1, what is the "y" in the part $e^{-y}$

_ And just need a little explanation on the "argmax" notation 

- What scenarios generally have a $\pi$ distribution of the Beta model? 

- Tuning the Beta prior 

ps. meaning what is our best guess of alpha and beta given what we know in the piror data?

how to tune:

1) find the mean/expectation = 0.45

and make sure $E(\pi) = \alpha/(\alpha + \beta) \sim 0.45$ holds 

ps. that gives us the ratio between the two parameters, are there other clues for these two should sum up?

```{r}
# Plot the Beta(45, 55) prior
plot_beta(45, 55)
```


### 3.2 The Binomial data model and likelihood function 

ps. that is the second element of the Bayesian Rules

- turning the head

  The likelihood function is knowing the result y = 30 as the constant and is a function of the prob $\pi$ 
  
- maximization 

  Author didn't explain how they found that pi = 0.6 maximize the likelihood function. But I know R can do it for us. And this really resembles *MLE*!
  
  
## 3.3 Beta posterior model 

The third/last element of the Bayes Rules and it is what we try to find the answer for. And it is a model of which variable? $\pi$!
How we re-estimate the prob distribution of some events after we update our knowledge about new data.

The ONGO data, the ROs get registered before the law and after law, OR registered in Year 1 and Year 2 and Year 3?

```{r}
plot_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50)
```

ps: neat plot! really intuitive to help you get the rationale


```{r}
summarize_beta_binomial(alpha = 45, beta = 55, y = 30, n = 50)
```

- How the posterior is built?

Function 3.8 is genius! And that's all we need to build the posterior as the case in the chunk above, alpha, beta, y and n. 

Q: what we quickly go through the meaning of kernel, certainly it is a general concept. We saw it in RD. But what it means exactly? 

### 3.4 Beta-Benomial model

- general form

$$ Y| \sim Bin (n, \pi)$$

$$\pi \sim Beta(\alpha, beta)$$

- posterior of pi


$$ \pi| (Y = y) \sim Beta (\alpha + y, \beta + n-y)$$





### 3.5 Simulation 

```{r}
set.seed(84735)
michelle_sim <- data.frame(pi = rbeta(10000, 45, 55)) %>% 
  mutate(y = rbinom(10000, size = 50, prob = pi))

ggplot(michelle_sim, aes(x = pi, y = y)) + 
  geom_point(aes(color = (y == 30)), size = 0.1)
```




```{r}
# Keep only the simulated pairs that match our data
michelle_posterior <- michelle_sim %>% 
  filter(y == 30)

# Plot the remaining pi values
ggplot(michelle_posterior, aes(x = pi)) + 
  geom_density()
```


```{r}
michelle_posterior %>% 
  summarize(mean(pi), sd(pi))
```


```{r}
nrow(michelle_posterior)
```


## Questions for the chapter

1. In what circumstances do we model pi with the Beta probability model?

2. Why define the likelihood function? The conditional prob is more intuitive to me.



## Practices for Beyes Rules Chapter 3

In the practices for this chapter, I intend to try as *few* commands as possible in the {bayesrules} package possible. Not sure if it is necessary?

### Excercise 3.1

- a. result of tuning several times 


```{r}
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 20, shape2 = 30))

```
- b. $\mu = 0.8$ --> a:b = 0.8: (1-0.8) a = 4b
plug in the equation of var of the distribution:

$$\frac{ab}{(a+b)^2(a+b+1)}= \frac{4b^2}{(5b)^2(5b+1)}= 0.05$$
$$4/25 = 0.05 * (5b +1)$$
```{r}
(4/25/0.05-1)/5
```

b = 0.44, a = 1.32


```{r}
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 1.32, shape2 = 0.44))
```

```{r}
# still think b = 3 looks good
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 12, shape2 = 3))
```
-c.

```{r}
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 90, shape2 =10))

```

-d. I think it should look like this? Dense at the two ends.

```{r}
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 1/2, shape2 =1/2))

```


### Excercise 3.9

- a. a= 8, b =2 | a = 1, b = 20

```{r}
# mean
8/(8+2)
1/(1+20)
```


$$\frac{ab}{(a+b)^2(a+b+1)}$$

```{r}
# variance
16/(100*11)
20/(21^2*22)
```


```{r}
```

- b.

```{r}
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 8, shape2 =2))

```

```{r}
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 1, shape2 =20))

```

- c.
North Dakota people' probability of using "pop" is high, around 0.8, there is some variation to this proportion but not big

Louisiana people have a very very low proportion of folks who say "pop", and the variance is even smaller. 



### Excercise 3.10

-a. calculate the posterior using the equation for  posterior of pi


$$ \pi| (Y = y) \sim Beta (\alpha + y, \beta + n-y)$$
```{r}
# for person 1
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 8 + 12, shape2 = 2 + 50 - 12))

```
```{r}
# for person 2
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 1 + 12, shape2 = 20 + 50 - 12))

```


- This is a simulated way that *DID NOT* work. Give more thought, I think the simulated data is in essense discrete, and it is impossible to calculate the probability at a particular value of "pi". So it does not work? 



```{r}
# model for Person 1
set.seed(5431)

pop_area1 <- tibble(prior = rbeta (1000, shape1 = 8, shape2 = 2)) %>% 
  mutate(likelihood = choose(50, 12) * prior^12 * (1-prior)^(50-12)) %>% 
# applying Equation 3.12, omitting the Gamma function as some constant that can be normalized later
# BUT SEEM TO BE WRONG - the y value of a continuous pdf is not the probability!  
  mutate(unnormalized = prior^(8-1) * (1 - prior)^(2-1) * likelihood) %>% 
  mutate(normalizing_constant = sum(unnormalized)) %>% 
  mutate(posterior = unnormalized / normalizing_constant)


ggplot(pop_area1, aes(x = posterior)) +
  geom_density()

```


b. plotting

```{r}
# person 1 using bayesrules functions

plot_beta_binomial(alpha = 8, beta = 2, y = 12, n = 50)
```

```{r}
# person 2 using bayesrules functions

plot_beta_binomial(alpha = 1, beta = 20, y = 12, n = 50)
```
-c. 

With the same data to update the understanding, the two salespeople's posterior are still different, A towards higher proportion, B towards lower proportion, but they are getting closer.  

### Excercise 3.12

-a. mean 15%, roughly ranging from 10% - 25%, 10.2% in 2017 is not used
```{r}
#identify a beta distribution by tuning 
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 15, shape2 = 85))

```

-b. y = 30, n = 90
```{r}
#identify a beta distribution by tuning 
ggplot() +
  geom_function(fun = ~dbeta(.x, shape1 = 15+30, shape2 = 85+90-30))

```

-c.
a = 15, b = 85, y = 30, n = 90

Plug in Equation 3.11

```{r}
#mean
(15+30)/(15+85+90)
#mode
(15+30-1)/(15+85+90-2)
#sd
sqrt((15+30)*(85+90-30)/((15+85+90)^2*(15+85+90+1)))
```

-d.

```{r}
plot_beta_binomial(alpha = 15, beta = 85, y = 30, n = 90)
```

Prior is updated with new data of higher proportion to have higher mean, and the variance seems to be smaller too. 

### Excersise 3.14

```{r}
summarize_beta_binomial(alpha = 2, beta = 3, y = 9, n = 30)
```


Will stop here, nothing new to practice for the questions below. 






